{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikacijski modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Učitavanje podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes, garlic, pepper, purple onion, seasoning, garbanzo beans, feta cheese crumbles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, ground black pepper, thyme, eggs, green tomatoes, yellow corn meal, milk, vegetable oil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, green chilies, grilled chicken breasts, garlic powder, yellow onion, soy sauce, butter, chicken livers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pepper, onions, garlic paste, milk, butter, salt, lemon juice, water, chili powder, passata, oil, ground cumin, boneless chicken skinless thigh, garam m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine  \\\n",
       "0  10259        greek   \n",
       "1  25693  southern_us   \n",
       "2  20130     filipino   \n",
       "3  22213       indian   \n",
       "4  13162       indian   \n",
       "\n",
       "                                                                                                                                                                                               ingredients  \n",
       "0                                                                           [romaine lettuce, black olives, grape tomatoes, garlic, pepper, purple onion, seasoning, garbanzo beans, feta cheese crumbles]  \n",
       "1                                                                    [plain flour, ground pepper, salt, tomatoes, ground black pepper, thyme, eggs, green tomatoes, yellow corn meal, milk, vegetable oil]  \n",
       "2                                                     [eggs, pepper, salt, mayonaise, cooking oil, green chilies, grilled chicken breasts, garlic powder, yellow onion, soy sauce, butter, chicken livers]  \n",
       "3                                                                                                                                                                      [water, vegetable oil, wheat, salt]  \n",
       "4  [black pepper, shallots, cornflour, cayenne pepper, onions, garlic paste, milk, butter, salt, lemon juice, water, chili powder, passata, oil, ground cumin, boneless chicken skinless thigh, garam m...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = './train.json'\n",
    "data = pd.read_json(train_path)\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podijeliti ćemo dostupan skup podataka na train i test set na 80-20% pri tome čuvajući omjer klasa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "X = data['ingredients']\n",
    "y = data['cuisine']\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n",
    "\n",
    "train_index, test_index = list(sss.split(X, y))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Izgradnja matrice u kojem redak predstavlja recept, a stupci sastojak. Ako je na (i, j) mjestu u matrici 1 to znaci da je j-ti sastojak zastupljen u i-tom receptu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svaki sastojak ćemo tokenizirati pomoću NLTK paketa, pretvoriti sva slova u mala, maknuti posebne znakove i na kraju provesti lemmatizaciju koristeći WordNetLemmatizer iz NLTK paketa. Sveukupno bi taj postupak na trening setu trebao trajati oko jedne minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj jedinstvenih sastojaka 2912\n",
      "CPU times: user 39.7 s, sys: 591 ms, total: 40.3 s\n",
      "Wall time: 40.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "\n",
    "def lemmantize(set_of_ing):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # unidecode(word).lower() smanjio sa 3341 na 2912\n",
    "    return set([lemmatizer.lemmatize(unidecode(word).lower()) \n",
    "                for word_list in [nltk.word_tokenize(ing) for ing in set_of_ing] \n",
    "                for word in word_list])\n",
    "\n",
    "ingredients_counter = Counter(ingredient for ingredients_list in X.apply(set).apply(lemmantize)\n",
    "                              for ingredient in ingredients_list)\n",
    "\n",
    "print(\"Broj jedinstvenih sastojaka\", len(ingredients_counter))\n",
    "\n",
    "ingredientToInd = dict([(y, x) for x, y in enumerate(ingredients_counter)])\n",
    "indToIngredient = dict([(x, y) for x, y in enumerate(ingredients_counter)])\n",
    "\n",
    "# trebat ce matrica len(train) x broj_jedinstvenih_sastojaka -> 39774 x 2912 = 267042636 ~ 2 * 10^8\n",
    "def create_cnt_matrix(ingredients_data):\n",
    "    processed_data = ingredients_data.apply(set).apply(lemmantize)\n",
    "    \n",
    "    cnt_matrix = lil_matrix((len(ingredients_data), len(ingredients_counter)), dtype=bool, copy=False)\n",
    "\n",
    "    for i, row in enumerate(processed_data):\n",
    "        for ingredient in row:\n",
    "            if ingredient in ingredientToInd:\n",
    "                cnt_matrix[i, ingredientToInd[ingredient]] = 1\n",
    "            \n",
    "    return cnt_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popunjenost matrice:  0.00645310668739919\n",
      "CPU times: user 43.2 s, sys: 71.8 ms, total: 43.3 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cnt_matrix = create_cnt_matrix(X)\n",
    "print(\"Popunjenost matrice: \", cnt_matrix.count_nonzero() / (cnt_matrix.shape[0] * cnt_matrix[1].shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naivni prediktor koji samo predviđa talijansku kuhinju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19705207580376505\n",
      "0.19710873664362036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class BaselineClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [\"italian\"] * X.shape[0]\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return sum(self.predict(X) == y) / X.shape[0]\n",
    "\n",
    "baseline = BaselineClassifier()\n",
    "\n",
    "print(\"training accuracy: \", baseline.score(X[train_index], y[train_index]))\n",
    "print(\"test accuracy: \", baseline.score(X[test_index], y[test_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naivni prediktor nam služi za referencu koliko dobro rade modeli strojnog učenja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treniranje raznih modela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 40 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/home/ltomic/anaconda3/envs/vjezbe/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed: 22.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 54s, sys: 1.48 s, total: 3min 56s\n",
      "Wall time: 26min 46s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.762791</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.762791</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.759271</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.759145</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.758642</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.758391</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.758265</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.758265</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.757008</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.756631</td>\n",
       "      <td>0.987429</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.755374</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.754494</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.754243</td>\n",
       "      <td>0.990446</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.753865</td>\n",
       "      <td>0.989597</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.751226</td>\n",
       "      <td>0.992363</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.750346</td>\n",
       "      <td>0.991797</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.749717</td>\n",
       "      <td>0.980860</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.749214</td>\n",
       "      <td>0.992960</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.749214</td>\n",
       "      <td>0.981709</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.748209</td>\n",
       "      <td>0.990666</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.746323</td>\n",
       "      <td>0.992269</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.745820</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.742678</td>\n",
       "      <td>0.947798</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.741043</td>\n",
       "      <td>0.947013</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.720553</td>\n",
       "      <td>0.959647</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.720050</td>\n",
       "      <td>0.957604</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.710748</td>\n",
       "      <td>0.906157</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.710119</td>\n",
       "      <td>0.902323</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.683972</td>\n",
       "      <td>0.914956</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.682464</td>\n",
       "      <td>0.911782</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.673287</td>\n",
       "      <td>0.842861</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.672659</td>\n",
       "      <td>0.841730</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.828342</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625896</td>\n",
       "      <td>0.829693</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.618102</td>\n",
       "      <td>0.754706</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.615336</td>\n",
       "      <td>0.751406</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.598762</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.505845</td>\n",
       "      <td>0.652032</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.499309</td>\n",
       "      <td>0.587448</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.494657</td>\n",
       "      <td>0.639775</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_n_estimators param_max_features  \\\n",
       "17            None                500                 50   \n",
       "13            None                500                 20   \n",
       "16            None                200                 50   \n",
       "19            None                500                 50   \n",
       "9             None                500                 10   \n",
       "5             None                500                  5   \n",
       "1             None                500                  2   \n",
       "12            None                200                 20   \n",
       "4             None                200                  5   \n",
       "18            None                200                 50   \n",
       "8             None                200                 10   \n",
       "0             None                200                  2   \n",
       "15            None                500                 20   \n",
       "14            None                200                 20   \n",
       "7             None                500                  5   \n",
       "11            None                500                 10   \n",
       "36              50                200                 50   \n",
       "3             None                500                  2   \n",
       "37              50                500                 50   \n",
       "10            None                200                 10   \n",
       "2             None                200                  2   \n",
       "6             None                200                  5   \n",
       "39              50                500                 50   \n",
       "38              50                200                 50   \n",
       "33              50                500                 20   \n",
       "32              50                200                 20   \n",
       "35              50                500                 20   \n",
       "34              50                200                 20   \n",
       "29              50                500                 10   \n",
       "28              50                200                 10   \n",
       "31              50                500                 10   \n",
       "30              50                200                 10   \n",
       "25              50                500                  5   \n",
       "24              50                200                  5   \n",
       "27              50                500                  5   \n",
       "26              50                200                  5   \n",
       "22              50                200                  2   \n",
       "21              50                500                  2   \n",
       "23              50                500                  2   \n",
       "20              50                200                  2   \n",
       "\n",
       "   param_min_samples_split  split0_test_score  split0_train_score  \\\n",
       "17                       2           0.762791            0.999749   \n",
       "13                       2           0.762791            0.999749   \n",
       "16                       2           0.759271            0.999749   \n",
       "19                       5           0.759145            0.988435   \n",
       "9                        2           0.758642            0.999749   \n",
       "5                        2           0.758391            0.999749   \n",
       "1                        2           0.758265            0.999749   \n",
       "12                       2           0.758265            0.999749   \n",
       "4                        2           0.757008            0.999749   \n",
       "18                       5           0.756631            0.987429   \n",
       "8                        2           0.755374            0.999749   \n",
       "0                        2           0.754494            0.999749   \n",
       "15                       5           0.754243            0.990446   \n",
       "14                       5           0.753865            0.989597   \n",
       "7                        5           0.751226            0.992363   \n",
       "11                       5           0.750346            0.991797   \n",
       "36                       2           0.749717            0.980860   \n",
       "3                        5           0.749214            0.992960   \n",
       "37                       2           0.749214            0.981709   \n",
       "10                       5           0.748209            0.990666   \n",
       "2                        5           0.746323            0.992269   \n",
       "6                        5           0.745820            0.991892   \n",
       "39                       5           0.742678            0.947798   \n",
       "38                       5           0.741043            0.947013   \n",
       "33                       2           0.720553            0.959647   \n",
       "32                       2           0.720050            0.957604   \n",
       "35                       5           0.710748            0.906157   \n",
       "34                       5           0.710119            0.902323   \n",
       "29                       2           0.683972            0.914956   \n",
       "28                       2           0.682464            0.911782   \n",
       "31                       5           0.673287            0.842861   \n",
       "30                       5           0.672659            0.841730   \n",
       "25                       2           0.627907            0.828342   \n",
       "24                       2           0.625896            0.829693   \n",
       "27                       5           0.618102            0.754706   \n",
       "26                       5           0.615336            0.751406   \n",
       "22                       5           0.511628            0.598762   \n",
       "21                       2           0.505845            0.652032   \n",
       "23                       5           0.499309            0.587448   \n",
       "20                       2           0.494657            0.639775   \n",
       "\n",
       "    rank_test_score  \n",
       "17                1  \n",
       "13                1  \n",
       "16                3  \n",
       "19                4  \n",
       "9                 5  \n",
       "5                 6  \n",
       "1                 7  \n",
       "12                7  \n",
       "4                 9  \n",
       "18               10  \n",
       "8                11  \n",
       "0                12  \n",
       "15               13  \n",
       "14               14  \n",
       "7                15  \n",
       "11               16  \n",
       "36               17  \n",
       "3                18  \n",
       "37               18  \n",
       "10               20  \n",
       "2                21  \n",
       "6                22  \n",
       "39               23  \n",
       "38               24  \n",
       "33               25  \n",
       "32               26  \n",
       "35               27  \n",
       "34               28  \n",
       "29               29  \n",
       "28               30  \n",
       "31               31  \n",
       "30               32  \n",
       "25               33  \n",
       "24               34  \n",
       "27               35  \n",
       "26               36  \n",
       "22               37  \n",
       "21               38  \n",
       "23               39  \n",
       "20               40  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [None, 50],\n",
    "              'min_samples_split': [2, 5],\n",
    "              'n_estimators': [200, 500],\n",
    "             'max_features': [2, 5, 10, 20, 50]} \n",
    "\n",
    "grid_random_forest = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3, n_jobs=4, \n",
    "                                  scoring='accuracy', return_train_score=True, cv = [(train_index, test_index)])\n",
    "\n",
    "grid_random_forest.fit(cnt_matrix, y)\n",
    "\n",
    "pd.DataFrame(grid_random_forest.cv_results_)[\n",
    "    ['param_max_depth', 'param_n_estimators', 'param_max_features', 'param_min_samples_split',\n",
    "     'split0_test_score', 'split0_train_score', 'rank_test_score']].sort_values(['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slučajne šume imaju savršen rezultat na trening setu, a na test setu imaju točnost od 76% posto. Tuniranjem hiperparametara dobivamo minimalno poboljšanje od 2%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koristimo SVM sa linearnom jezgrom (Yang, Liu : A re-examination of text categorization methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 144 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-2)]: Done 114 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-2)]: Done 144 out of 144 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.54 s, sys: 1.07 s, total: 9.61 s\n",
      "Wall time: 7min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltomic/anaconda3/envs/vjezbe/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.771716</td>\n",
       "      <td>0.825356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.771716</td>\n",
       "      <td>0.825324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770207</td>\n",
       "      <td>0.865269</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770082</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.759271</td>\n",
       "      <td>0.882209</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>squared hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>squared hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>squared hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>5000</td>\n",
       "      <td>squared hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_C     param_loss param_penalty param_max_iter param_class_weight  \\\n",
       "19      0.1          hinge            l2           2000               None   \n",
       "17      0.1          hinge            l2           1000               None   \n",
       "35        1          hinge            l2           2000               None   \n",
       "33        1          hinge            l2           1000               None   \n",
       "51       10          hinge            l2           2000               None   \n",
       "..      ...            ...           ...            ...                ...   \n",
       "46        1  squared hinge            l1           2000           balanced   \n",
       "45        1  squared hinge            l2           1000           balanced   \n",
       "44        1  squared hinge            l1           1000           balanced   \n",
       "40        1          hinge            l1           1000           balanced   \n",
       "143    5000  squared hinge            l2           2000           balanced   \n",
       "\n",
       "     split0_test_score  split0_train_score  rank_test_score  \n",
       "19            0.771716            0.825356                1  \n",
       "17            0.771716            0.825324                1  \n",
       "35            0.770207            0.865269                3  \n",
       "33            0.770082            0.865426                4  \n",
       "51            0.759271            0.882209                5  \n",
       "..                 ...                 ...              ...  \n",
       "46                 NaN                 NaN              140  \n",
       "45                 NaN                 NaN              141  \n",
       "44                 NaN                 NaN              142  \n",
       "40                 NaN                 NaN              143  \n",
       "143                NaN                 NaN              144  \n",
       "\n",
       "[144 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.1, 1, 10, 50, 100, 500, 1000, 5000],  \n",
    "              'penalty': ['l1','l2'],\n",
    "             'loss': ['hinge','squared hinge'],\n",
    "             'class_weight': [None, 'balanced'],\n",
    "             'max_iter': [1000, 2000]} \n",
    "\n",
    "grid_linear_svm = GridSearchCV(LinearSVC(), param_grid, refit = True, verbose = 3, n_jobs=-2, scoring='accuracy',\n",
    "                       return_train_score=True, cv = [(train_index, test_index)])\n",
    "\n",
    "grid_linear_svm.fit(cnt_matrix, y)\n",
    "\n",
    "pd.DataFrame(grid_linear_svm.cv_results_)[\n",
    "    ['param_C', 'param_loss', 'param_penalty', 'param_max_iter', 'param_class_weight', 'split0_test_score', \n",
    "     'split0_train_score', 'rank_test_score']].sort_values(['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.771716</td>\n",
       "      <td>0.825356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.771716</td>\n",
       "      <td>0.825324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770207</td>\n",
       "      <td>0.865269</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770082</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.759271</td>\n",
       "      <td>0.882209</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.759271</td>\n",
       "      <td>0.881957</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.754243</td>\n",
       "      <td>0.816808</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.754243</td>\n",
       "      <td>0.816808</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.753740</td>\n",
       "      <td>0.854961</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.753488</td>\n",
       "      <td>0.854929</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>50</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.749717</td>\n",
       "      <td>0.885006</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>50</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.748586</td>\n",
       "      <td>0.882523</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>100</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.738026</td>\n",
       "      <td>0.880700</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.736266</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>10</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>50</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.721936</td>\n",
       "      <td>0.862001</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>50</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.720805</td>\n",
       "      <td>0.863415</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>100</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.719547</td>\n",
       "      <td>0.861152</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>100</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.719422</td>\n",
       "      <td>0.862849</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>5000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.716782</td>\n",
       "      <td>0.832521</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>500</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.715399</td>\n",
       "      <td>0.829096</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>500</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.713765</td>\n",
       "      <td>0.828970</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.712885</td>\n",
       "      <td>0.825073</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.707228</td>\n",
       "      <td>0.825576</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>100</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.706977</td>\n",
       "      <td>0.831076</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>500</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.705971</td>\n",
       "      <td>0.830699</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>5000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.702577</td>\n",
       "      <td>0.819165</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>500</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.701823</td>\n",
       "      <td>0.817499</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.696794</td>\n",
       "      <td>0.812093</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.696040</td>\n",
       "      <td>0.808573</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_C param_loss param_penalty param_max_iter param_class_weight  \\\n",
       "19      0.1      hinge            l2           2000               None   \n",
       "17      0.1      hinge            l2           1000               None   \n",
       "35        1      hinge            l2           2000               None   \n",
       "33        1      hinge            l2           1000               None   \n",
       "51       10      hinge            l2           2000               None   \n",
       "49       10      hinge            l2           1000               None   \n",
       "27      0.1      hinge            l2           2000           balanced   \n",
       "25      0.1      hinge            l2           1000           balanced   \n",
       "41        1      hinge            l2           1000           balanced   \n",
       "43        1      hinge            l2           2000           balanced   \n",
       "67       50      hinge            l2           2000               None   \n",
       "65       50      hinge            l2           1000               None   \n",
       "83      100      hinge            l2           2000               None   \n",
       "59       10      hinge            l2           2000           balanced   \n",
       "57       10      hinge            l2           1000           balanced   \n",
       "73       50      hinge            l2           1000           balanced   \n",
       "75       50      hinge            l2           2000           balanced   \n",
       "81      100      hinge            l2           1000               None   \n",
       "91      100      hinge            l2           2000           balanced   \n",
       "129    5000      hinge            l2           1000               None   \n",
       "97      500      hinge            l2           1000               None   \n",
       "99      500      hinge            l2           2000               None   \n",
       "113    1000      hinge            l2           1000               None   \n",
       "123    1000      hinge            l2           2000           balanced   \n",
       "89      100      hinge            l2           1000           balanced   \n",
       "107     500      hinge            l2           2000           balanced   \n",
       "131    5000      hinge            l2           2000               None   \n",
       "105     500      hinge            l2           1000           balanced   \n",
       "139    5000      hinge            l2           2000           balanced   \n",
       "121    1000      hinge            l2           1000           balanced   \n",
       "\n",
       "     split0_test_score  split0_train_score  rank_test_score  \n",
       "19            0.771716            0.825356                1  \n",
       "17            0.771716            0.825324                1  \n",
       "35            0.770207            0.865269                3  \n",
       "33            0.770082            0.865426                4  \n",
       "51            0.759271            0.882209                5  \n",
       "49            0.759271            0.881957                5  \n",
       "27            0.754243            0.816808                7  \n",
       "25            0.754243            0.816808                7  \n",
       "41            0.753740            0.854961                9  \n",
       "43            0.753488            0.854929               10  \n",
       "67            0.749717            0.885006               11  \n",
       "65            0.748586            0.882523               12  \n",
       "83            0.738026            0.880700               13  \n",
       "59            0.736266            0.868852               14  \n",
       "57            0.735512            0.868852               15  \n",
       "73            0.721936            0.862001               16  \n",
       "75            0.720805            0.863415               17  \n",
       "81            0.719547            0.861152               18  \n",
       "91            0.719422            0.862849               19  \n",
       "129           0.716782            0.832521               20  \n",
       "97            0.715399            0.829096               21  \n",
       "99            0.713765            0.828970               22  \n",
       "113           0.712885            0.825073               23  \n",
       "123           0.707228            0.825576               24  \n",
       "89            0.706977            0.831076               25  \n",
       "107           0.705971            0.830699               26  \n",
       "131           0.702577            0.819165               27  \n",
       "105           0.701823            0.817499               28  \n",
       "139           0.696794            0.812093               29  \n",
       "121           0.696040            0.808573               30  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_linear_svm.cv_results_)[\n",
    "    ['param_C', 'param_loss', 'param_penalty', 'param_max_iter', 'param_class_weight', 'split0_test_score', \n",
    "     'split0_train_score', 'rank_test_score']].sort_values(['rank_test_score']).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linearni SVM je mrvicu bolji od slučajnih šuma - 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "gaussian_nb.fit(cnt_matrix[train_index].toarray(), y[train_index])\n",
    "\n",
    "%%time\n",
    "\n",
    "print(\"train score: \", gaussian_nb.score(cnt_matrix[train_index].toarray(), y[train_index]))\n",
    "print(\"test score: \", gaussian_nb.score(cnt_matrix[test_index].toarray(), y[test_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multinomial naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 202 candidates, totalling 202 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-2)]: Done 114 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-2)]: Done 202 out of 202 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.76 s, sys: 528 ms, total: 6.29 s\n",
      "Wall time: 23.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_fit_prior</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.83</td>\n",
       "      <td>True</td>\n",
       "      <td>0.730987</td>\n",
       "      <td>0.752946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.84</td>\n",
       "      <td>True</td>\n",
       "      <td>0.730861</td>\n",
       "      <td>0.752789</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.85</td>\n",
       "      <td>True</td>\n",
       "      <td>0.730861</td>\n",
       "      <td>0.752601</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.82</td>\n",
       "      <td>True</td>\n",
       "      <td>0.730735</td>\n",
       "      <td>0.753198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>0.730735</td>\n",
       "      <td>0.752538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.07</td>\n",
       "      <td>False</td>\n",
       "      <td>0.693652</td>\n",
       "      <td>0.734687</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.693652</td>\n",
       "      <td>0.733901</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.09</td>\n",
       "      <td>False</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.734184</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>0.693023</td>\n",
       "      <td>0.734467</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.680075</td>\n",
       "      <td>0.751878</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_alpha param_fit_prior  split0_test_score  split0_train_score  \\\n",
       "167        0.83            True           0.730987            0.752946   \n",
       "169        0.84            True           0.730861            0.752789   \n",
       "171        0.85            True           0.730861            0.752601   \n",
       "165        0.82            True           0.730735            0.753198   \n",
       "181         0.9            True           0.730735            0.752538   \n",
       "..          ...             ...                ...                 ...   \n",
       "14         0.07           False           0.693652            0.734687   \n",
       "20          0.1           False           0.693652            0.733901   \n",
       "18         0.09           False           0.693400            0.734184   \n",
       "16         0.08           False           0.693023            0.734467   \n",
       "0           0.0           False           0.680075            0.751878   \n",
       "\n",
       "     rank_test_score  \n",
       "167                1  \n",
       "169                2  \n",
       "171                2  \n",
       "165                4  \n",
       "181                4  \n",
       "..               ...  \n",
       "14               198  \n",
       "20               198  \n",
       "18               200  \n",
       "16               201  \n",
       "0                202  \n",
       "\n",
       "[202 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "param_grid = {'alpha': [i * 0.01 for i in range(101)],\n",
    "              'fit_prior': [False, True]\n",
    "             } \n",
    "\n",
    "grid_multinomialNB = GridSearchCV(MultinomialNB(), param_grid, refit = True, verbose = 3, \n",
    "                                   n_jobs=-2, scoring='accuracy', cv = [(train_index, test_index)],\n",
    "                                   return_train_score=True)\n",
    "\n",
    "grid_multinomialNB.fit(cnt_matrix, y) \n",
    "\n",
    "pd.DataFrame(grid_multinomialNB.cv_results_)[\n",
    "    ['param_alpha', 'param_fit_prior', \n",
    "     'split0_test_score', 'split0_train_score', 'rank_test_score']].sort_values(['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naivni bayes je mrvicu lošiji od linearnog SVM, ali je puno brži algoritam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/naive_bayes.html#complement-naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 202 candidates, totalling 202 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-2)]: Done 114 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-2)]: Done 202 out of 202 | elapsed:   22.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.82 s, sys: 284 ms, total: 6.11 s\n",
      "Wall time: 22.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_norm</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.14</td>\n",
       "      <td>True</td>\n",
       "      <td>0.693526</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.17</td>\n",
       "      <td>True</td>\n",
       "      <td>0.693526</td>\n",
       "      <td>0.715547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.13</td>\n",
       "      <td>True</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.716962</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.27</td>\n",
       "      <td>True</td>\n",
       "      <td>0.693275</td>\n",
       "      <td>0.713190</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.693275</td>\n",
       "      <td>0.711839</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.683218</td>\n",
       "      <td>0.709199</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.98</td>\n",
       "      <td>True</td>\n",
       "      <td>0.683218</td>\n",
       "      <td>0.698482</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.682841</td>\n",
       "      <td>0.698419</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>0.676430</td>\n",
       "      <td>0.698199</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.343683</td>\n",
       "      <td>0.360068</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_alpha param_norm  split0_test_score  split0_train_score  \\\n",
       "29         0.14       True           0.693526            0.716867   \n",
       "35         0.17       True           0.693526            0.715547   \n",
       "27         0.13       True           0.693400            0.716962   \n",
       "55         0.27       True           0.693275            0.713190   \n",
       "61          0.3       True           0.693275            0.711839   \n",
       "..          ...        ...                ...                 ...   \n",
       "0           0.0      False           0.683218            0.709199   \n",
       "197        0.98       True           0.683218            0.698482   \n",
       "201         1.0       True           0.682841            0.698419   \n",
       "3          0.01       True           0.676430            0.698199   \n",
       "1           0.0       True           0.343683            0.360068   \n",
       "\n",
       "     rank_test_score  \n",
       "29                 1  \n",
       "35                 1  \n",
       "27                 3  \n",
       "55                 4  \n",
       "61                 4  \n",
       "..               ...  \n",
       "0                197  \n",
       "197              197  \n",
       "201              200  \n",
       "3                201  \n",
       "1                202  \n",
       "\n",
       "[202 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "param_grid = {'alpha': [i * 0.01 for i in range(101)],\n",
    "              'norm': [False, True]\n",
    "             } \n",
    "\n",
    "grid_complementNB = GridSearchCV(ComplementNB(), param_grid, refit = True, verbose = 3, \n",
    "                                   n_jobs=-2, scoring='accuracy', cv = [(train_index, test_index)],\n",
    "                                   return_train_score=True)\n",
    "\n",
    "grid_complementNB.fit(cnt_matrix, y) \n",
    "\n",
    "pd.DataFrame(grid_complementNB.cv_results_)[\n",
    "    ['param_alpha', 'param_norm', \n",
    "     'split0_test_score', 'split0_train_score', 'rank_test_score']].sort_values(['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 202 candidates, totalling 202 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-2)]: Done 114 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-2)]: Done 202 out of 202 | elapsed:   23.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_fit_prior</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.68</td>\n",
       "      <td>True</td>\n",
       "      <td>0.720302</td>\n",
       "      <td>0.739590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.66</td>\n",
       "      <td>True</td>\n",
       "      <td>0.720302</td>\n",
       "      <td>0.739810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.720176</td>\n",
       "      <td>0.741255</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.63</td>\n",
       "      <td>True</td>\n",
       "      <td>0.720050</td>\n",
       "      <td>0.740407</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.65</td>\n",
       "      <td>True</td>\n",
       "      <td>0.720050</td>\n",
       "      <td>0.739904</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.680704</td>\n",
       "      <td>0.717810</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.06</td>\n",
       "      <td>False</td>\n",
       "      <td>0.680327</td>\n",
       "      <td>0.716742</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.03</td>\n",
       "      <td>False</td>\n",
       "      <td>0.680201</td>\n",
       "      <td>0.719539</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>0.679195</td>\n",
       "      <td>0.721456</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.670522</td>\n",
       "      <td>0.737641</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_alpha param_fit_prior  split0_test_score  split0_train_score  \\\n",
       "137        0.68            True           0.720302            0.739590   \n",
       "133        0.66            True           0.720302            0.739810   \n",
       "121         0.6            True           0.720176            0.741255   \n",
       "127        0.63            True           0.720050            0.740407   \n",
       "131        0.65            True           0.720050            0.739904   \n",
       "..          ...             ...                ...                 ...   \n",
       "10         0.05           False           0.680704            0.717810   \n",
       "12         0.06           False           0.680327            0.716742   \n",
       "6          0.03           False           0.680201            0.719539   \n",
       "4          0.02           False           0.679195            0.721456   \n",
       "0           0.0           False           0.670522            0.737641   \n",
       "\n",
       "     rank_test_score  \n",
       "137                1  \n",
       "133                1  \n",
       "121                3  \n",
       "127                4  \n",
       "131                4  \n",
       "..               ...  \n",
       "10               198  \n",
       "12               199  \n",
       "6                200  \n",
       "4                201  \n",
       "0                202  \n",
       "\n",
       "[202 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "param_grid = {'alpha': [i * 0.01 for i in range(101)],\n",
    "              'fit_prior': [False, True]\n",
    "             } \n",
    "\n",
    "grid_bernoulliNB = GridSearchCV(BernoulliNB(), param_grid, refit = True, verbose = 3, \n",
    "                                   n_jobs=-2, scoring='accuracy', cv = [(train_index, test_index)],\n",
    "                                   return_train_score=True)\n",
    "grid_bernoulliNB.fit(cnt_matrix, y) \n",
    "\n",
    "pd.DataFrame(grid_bernoulliNB.cv_results_)[\n",
    "    ['param_alpha', 'param_fit_prior', \n",
    "     'split0_test_score', 'split0_train_score', 'rank_test_score']].sort_values(['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 48 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=6)]: Done  48 out of  48 | elapsed: 32.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 40s, sys: 488 ms, total: 2min 40s\n",
      "Wall time: 35min 21s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.757134</td>\n",
       "      <td>0.885069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>80</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.748209</td>\n",
       "      <td>0.939124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.745066</td>\n",
       "      <td>0.865866</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.742426</td>\n",
       "      <td>0.924039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.739158</td>\n",
       "      <td>0.798139</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.738529</td>\n",
       "      <td>0.834627</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.738278</td>\n",
       "      <td>0.897985</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732747</td>\n",
       "      <td>0.783368</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.727593</td>\n",
       "      <td>0.840661</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.722313</td>\n",
       "      <td>0.842893</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.722062</td>\n",
       "      <td>0.819793</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>80</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.720553</td>\n",
       "      <td>0.840441</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.717788</td>\n",
       "      <td>0.761495</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>80</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716153</td>\n",
       "      <td>0.736478</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.716028</td>\n",
       "      <td>0.750149</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>60</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.710497</td>\n",
       "      <td>0.809831</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.709742</td>\n",
       "      <td>0.780320</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>0.731198</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700943</td>\n",
       "      <td>0.721927</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.692269</td>\n",
       "      <td>0.718753</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>80</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685481</td>\n",
       "      <td>0.709042</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>60</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.684852</td>\n",
       "      <td>0.706622</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.681584</td>\n",
       "      <td>0.702285</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.679950</td>\n",
       "      <td>0.698608</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.679824</td>\n",
       "      <td>0.703982</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.678944</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.665493</td>\n",
       "      <td>0.678023</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645255</td>\n",
       "      <td>0.656055</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643495</td>\n",
       "      <td>0.654200</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.634821</td>\n",
       "      <td>0.651466</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>60</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631804</td>\n",
       "      <td>0.645621</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631804</td>\n",
       "      <td>0.645621</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631050</td>\n",
       "      <td>0.644363</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.615211</td>\n",
       "      <td>0.628681</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.614582</td>\n",
       "      <td>0.626230</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.586424</td>\n",
       "      <td>0.626072</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.569076</td>\n",
       "      <td>0.619693</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559774</td>\n",
       "      <td>0.569440</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558642</td>\n",
       "      <td>0.608347</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.535889</td>\n",
       "      <td>0.585216</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503708</td>\n",
       "      <td>0.512681</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503708</td>\n",
       "      <td>0.512681</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503708</td>\n",
       "      <td>0.512681</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503583</td>\n",
       "      <td>0.512681</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124073</td>\n",
       "      <td>0.122631</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124073</td>\n",
       "      <td>0.122631</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124073</td>\n",
       "      <td>0.122663</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124073</td>\n",
       "      <td>0.122663</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_learning_rate param_max_depth  split0_test_score  \\\n",
       "11                 80                 0.1               5           0.757134   \n",
       "23                 80                0.25               5           0.748209   \n",
       "10                 60                 0.1               5           0.745066   \n",
       "22                 60                0.25               5           0.742426   \n",
       "19                 80                0.25               2           0.739158   \n",
       "9                  40                 0.1               5           0.738529   \n",
       "21                 40                0.25               5           0.738278   \n",
       "18                 60                0.25               2           0.732747   \n",
       "33                 40                 0.5               5           0.727593   \n",
       "20                 20                0.25               5           0.722313   \n",
       "32                 20                 0.5               5           0.722062   \n",
       "35                 80                 0.5               5           0.720553   \n",
       "17                 40                0.25               2           0.717788   \n",
       "15                 80                0.25               1           0.716153   \n",
       "7                  80                 0.1               2           0.716028   \n",
       "34                 60                 0.5               5           0.710497   \n",
       "8                  20                 0.1               5           0.709742   \n",
       "6                  60                 0.1               2           0.703331   \n",
       "14                 60                0.25               1           0.700943   \n",
       "16                 20                0.25               2           0.692269   \n",
       "31                 80                 0.5               2           0.685481   \n",
       "30                 60                 0.5               2           0.684852   \n",
       "5                  40                 0.1               2           0.681584   \n",
       "13                 40                0.25               1           0.679950   \n",
       "28                 20                 0.5               2           0.679824   \n",
       "29                 40                 0.5               2           0.678944   \n",
       "3                  80                 0.1               1           0.665493   \n",
       "2                  60                 0.1               1           0.645255   \n",
       "12                 20                0.25               1           0.643495   \n",
       "4                  20                 0.1               2           0.634821   \n",
       "26                 60                 0.5               1           0.631804   \n",
       "27                 80                 0.5               1           0.631804   \n",
       "25                 40                 0.5               1           0.631050   \n",
       "1                  40                 0.1               1           0.615211   \n",
       "24                 20                 0.5               1           0.614582   \n",
       "46                 60                   1               5           0.586424   \n",
       "44                 20                   1               5           0.569076   \n",
       "0                  20                 0.1               1           0.559774   \n",
       "47                 80                   1               5           0.558642   \n",
       "45                 40                   1               5           0.535889   \n",
       "38                 60                   1               1           0.503708   \n",
       "39                 80                   1               1           0.503708   \n",
       "37                 40                   1               1           0.503708   \n",
       "36                 20                   1               1           0.503583   \n",
       "40                 20                   1               2           0.124073   \n",
       "41                 40                   1               2           0.124073   \n",
       "42                 60                   1               2           0.124073   \n",
       "43                 80                   1               2           0.124073   \n",
       "\n",
       "    split0_train_score  rank_test_score  \n",
       "11            0.885069                1  \n",
       "23            0.939124                2  \n",
       "10            0.865866                3  \n",
       "22            0.924039                4  \n",
       "19            0.798139                5  \n",
       "9             0.834627                6  \n",
       "21            0.897985                7  \n",
       "18            0.783368                8  \n",
       "33            0.840661                9  \n",
       "20            0.842893               10  \n",
       "32            0.819793               11  \n",
       "35            0.840441               12  \n",
       "17            0.761495               13  \n",
       "15            0.736478               14  \n",
       "7             0.750149               15  \n",
       "34            0.809831               16  \n",
       "8             0.780320               17  \n",
       "6             0.731198               18  \n",
       "14            0.721927               19  \n",
       "16            0.718753               20  \n",
       "31            0.709042               21  \n",
       "30            0.706622               22  \n",
       "5             0.702285               23  \n",
       "13            0.698608               24  \n",
       "28            0.703982               25  \n",
       "29            0.697885               26  \n",
       "3             0.678023               27  \n",
       "2             0.656055               28  \n",
       "12            0.654200               29  \n",
       "4             0.651466               30  \n",
       "26            0.645621               31  \n",
       "27            0.645621               31  \n",
       "25            0.644363               33  \n",
       "1             0.628681               34  \n",
       "24            0.626230               35  \n",
       "46            0.626072               36  \n",
       "44            0.619693               37  \n",
       "0             0.569440               38  \n",
       "47            0.608347               39  \n",
       "45            0.585216               40  \n",
       "38            0.512681               41  \n",
       "39            0.512681               41  \n",
       "37            0.512681               41  \n",
       "36            0.512681               44  \n",
       "40            0.122631               45  \n",
       "41            0.122631               45  \n",
       "42            0.122663               45  \n",
       "43            0.122663               45  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = {'n_estimators': [i*20 for i in range(1, 5)],\n",
    "              'learning_rate': [0.1, 0.25, 0.5, 1],\n",
    "              'max_depth': [1, 2, 5]\n",
    "             } \n",
    "\n",
    "grid_grad_boost = GridSearchCV(GradientBoostingClassifier(), param_grid, refit = True, verbose = 3, \n",
    "                                   n_jobs=6, scoring='accuracy', cv = [(train_index, test_index)],\n",
    "                                   return_train_score=True)\n",
    "grid_grad_boost.fit(cnt_matrix, y) \n",
    "\n",
    "pd.DataFrame(grid_grad_boost.cv_results_)[\n",
    "    ['param_n_estimators', 'param_learning_rate', 'param_max_depth',\n",
    "     'split0_test_score', 'split0_train_score', 'rank_test_score']].sort_values(['rank_test_score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vjezbe",
   "language": "python",
   "name": "vjezbe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
